{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Assignment Report for Pattern Recognition\n",
    "Name:  陳　鵬　(Chen Peng) <br>\n",
    "Lab:   Yoshikawa & Ma Laboratory <br>\n",
    "StuID: 6930-30-2948 <br>\n",
    "Email: chenpeng.acmer@yahoo.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------\n",
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Data Explanation\n",
    "### The data set \"Wine\", downloaded from UCI Irvine Machine Learning Repository, is being used in the following analysis. Data in \"Wine\" are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars which actually form the categories we want to classify in the task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The attribute set consists of the quantities of 13 constituents found in each of the three types of wines:\n",
    "1) Alcohol <br>\n",
    "2) Malic acid <br>\n",
    "3) Ash <br>\n",
    "4) Alcalinity of ash <br>\n",
    "5) Magnesium <br>\n",
    "6) Total phenols <br>\n",
    "7) Flavanoids <br>\n",
    "8) Nonflavanoid phenols <br>\n",
    "9) Proanthocyanins <br>\n",
    "10) Color intensity <br>\n",
    "11) Hue <br>\n",
    "12) OD280/OD315 of diluted wines <br>\n",
    "13) Proline <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are three classes (cultivars). Class distribution: (number of instances per class)\n",
    "class 1: 59 <br>\n",
    "class 2: 71 <br>\n",
    "class 3: 48 <br>\n",
    "Total: 178 instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  All attributes are continuous. No missing attribute values. \n",
    "### An example follows:\n",
    "class=2, Alcohol=12.67, Malic acid=0.98, Ash=2.24, Alcalinity of ash=18, Magnesium=99, Total phenols=2.2, Flavanoids=1.94, Nonflavanoid phenols=0.3, Proanthocyanins=1.46, Color intensity=2.62, Hue=1.23, OD280/OD315 of diluted wines=3.16, Proline=450"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Objective: ternary classifiction\n",
    "### Given an instance in \"Wine\" with 13 attributes, classifiy it as one of three types of wines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------\n",
    "# 2. Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Generative Models: Gaussian Bayes Classifier\n",
    "## (1) Analysis\n",
    "### From the example above, we find that all attributes, such as \"Alcohol\", \"Proline\" and \"Malic acid\" are continuous, not discrete. There is an assumption that data from each class is drawn from a simple Gaussian distribution. \n",
    "#### Here is the distribution of ith attribute of instances of class K.\n",
    "$$ p(x_{i}|C_{k}) = \\frac{1}{(2\\pi)^{D/2}|\\Sigma|_{k,i}^{1/2}   } exp\\{ -\\frac{1}{2}(x_{i}-\\mu_{k, i})^{T}\\Sigma_{k,i}^{-1}(x_{i}-\\mu_{k,i})\\} = \\mathcal{N}(x_{i}|\\mu_{k,i}, \\Sigma_{k,i})\n",
    " $$\n",
    "\n",
    "#### $$ x_{i}:\\text{the ith attribute of x},\\ \\ \\mu_{k,i}: mean,\\ \\ \\Sigma_{k,i}: \\text{covariance matrix of ith attribute in class k}, \\ \\ D: dim(x_{i}) $$\n",
    "\n",
    "### Here, we introduce another assumption, named attribute conditional independence assumption, which is adopted in Naive Bayes Classifier. Then, we have:\n",
    "$$ p(x|C_{k}) = \\prod_{i=1}^{d}p(x_{i}|C_{k}) = \\prod_{i=1}^{d}\\mathcal{N} (x_{i}| \\mu_{k,i}, \\Sigma_{k,i} ), \\ \\ d: number \\ of \\ attributes, \\ here, \\ d = 13 $$\n",
    "\n",
    "### In this case of three classes, the posterior probability for class k can be written as:\n",
    "$$ p(C_{k}|x) = \\frac{p(x|C_{k})p(C_{k})}{p(x)}=\\frac{p(x|C_{k})p(C_{k})}{\\sum_{j}p(x|C_{j})p(C_{j})} = \\frac{exp(a_k)}{\\sum_{j}exp(a_{j})} $$\n",
    "### where\n",
    "$$ a_{k} = ln(p(x|C_{k})p(C_{k})) $$\n",
    "\n",
    "### Here we know how to calculate the posterior probability as long as we get parameters of all distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Maximum likelihood solution: Parameter Estimation\n",
    "### Here, we have a data set  {xn, Cn}  where  n = 1,2,3 ... N, where Cn = 1 denotes class 1, Cn = 2 denotes class 2 and Cn = 3 for class 3.\n",
    "### We have $$ p(x_{n}, C_{k}) = p(C_{k})p(x_{n}|C_{k}) = p(C_{k}) \\prod_{i=1}^{d}\\mathcal{N} (x_{n,i}| \\mu_{k,i}, \\Sigma_{k,i} ) $$\n",
    "### Therefore, the likelihood is given by\n",
    "$$ p(x, C) = \\prod_{n=1}^{N}p(x_{n}, C_{n}) = \\prod_{n=1}^{N}\\prod_{i=1}^{d}p(C_{n}) \\mathcal{N}(x_{n,i}| \\mu_{k,i}, \\Sigma_{k,i}) $$\n",
    "### To maximize the likelihood, we need to calculate derivatives with respect to each parameter. Here the derivation process is omitted. Then we obtain\n",
    "$$ p(C_{k}) = \\frac{N_{k}}{N} $$\n",
    "$$ \\mu_{k,i} = \\frac{1}{N_{k}} \\sum_{class = k} x_{n,i} $$\n",
    "$$  \\Sigma_{k,i} = \\frac{1}{N_{k}} \\sum_{n\\in C_{k}}(x_{n,i} - \\mu_{n,i})^{T}(x_{n,i} - \\mu_{n,i}) $$\n",
    "\n",
    "### It is worth mentioning that if we the share covariance matrix among all attributes and classes, the shared matrix could be a weighted average of all covariance matrices $ \\Sigma_{k,i} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Until here, we have got all parameters for all Gaussian distributions. Then, given an instance in the test set, the posterior probabilities $ p(C_{k}|x) $ could be calculated by using softmax function, and the result becomes\n",
    "$$ class \\ of \\ x = argmax_{k \\in C}\\ p(C_{k}|x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------\n",
    "# 3. Experiment\n",
    "\n",
    "### (1) Split data set\n",
    "### In the experiment, the data set is randomly divided into two parts: the training set A and the test set B.\n",
    "### Total size: 178, Size of A: 142, Size of B: 36.  Ratio: 8 : 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total size of the data set: 178\n",
      "Size of trianing set: 142. Size of test set: 36.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "\n",
    "with open('wine.data', 'r') as file:\n",
    "    wine = [line for line in csv.reader(file)]\n",
    "print('The total size of the data set: {}'.format(len(wine)))\n",
    "\n",
    "training_size = int(0.8 * len(wine))\n",
    "training_set = []\n",
    "test_size = len(wine) - training_size\n",
    "test_set = []\n",
    "\n",
    "training_count = 0\n",
    "copy_wine = wine.copy()\n",
    "while(training_count < training_size):\n",
    "    idx = random.randint(0, len(copy_wine)-1)\n",
    "    training_set.append(copy_wine[idx])\n",
    "    copy_wine.pop(idx)\n",
    "    training_count += 1\n",
    "test_set = copy_wine.copy()\n",
    "\n",
    "print('Size of trianing set: {}. Size of test set: {}.'.format(len(training_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Parameter Estimation: calculate $ \\mu_{k,i} $ and $ \\Sigma_{k,i} $ where k = 1,2,3 and i = 1,2, ... , size of set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMu(data_set):\n",
    "    mu = [[0 for i in range(13)] for j in range(3)] # size: 3 * 13\n",
    "    count = [0 for i in range(3)] # size: 3, count the number of classes\n",
    "    for item in data_set: # iterate all instances in this set\n",
    "        class_id = int(item[0])\n",
    "        count[class_id - 1] += 1\n",
    "        for j in range(1, 14):\n",
    "            mu[class_id - 1][j - 1] += float(item[j])\n",
    "    for i in range(3):\n",
    "        for j in range(13):\n",
    "            mu[i][j] /= float(count[i])\n",
    "    return mu\n",
    "\n",
    "def getSigma(data_set, mu):\n",
    "    Sigma = [[0 for i in range(13)] for j in range(3)] # size: 3 * 13\n",
    "    count = [0 for i in range(3)] # size: 3, count the number of classes\n",
    "    for item in data_set:\n",
    "        class_id = int(item[0])\n",
    "        count[class_id - 1] += 1\n",
    "        for j in range(1, 14):\n",
    "            Sigma[class_id - 1][j - 1] += (float(item[j]) - mu[class_id - 1][j - 1]) ** 2\n",
    "    for i in range(3):\n",
    "        for j in range(13):\n",
    "            Sigma[i][j] /= float(count[i])\n",
    "    return Sigma\n",
    "\n",
    "def getPCk(data_set):\n",
    "    count = [0 for i in range(3)]\n",
    "    for item in data_set:\n",
    "        class_id = int(item[0])\n",
    "        count[class_id - 1] += 1\n",
    "    return count\n",
    "\n",
    "training_mu = getMu(training_set)\n",
    "training_Sigma = getSigma(training_set, training_mu)\n",
    "pCk = getPCk(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Evaluation: given an instance in test set, calculate $  a_{k}$ for each class, then use softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Ground Truth: 1, Classification: 1, Correct\n",
      "1: Ground Truth: 1, Classification: 1, Correct\n",
      "2: Ground Truth: 1, Classification: 1, Correct\n",
      "3: Ground Truth: 1, Classification: 1, Correct\n",
      "4: Ground Truth: 1, Classification: 1, Correct\n",
      "5: Ground Truth: 1, Classification: 1, Correct\n",
      "6: Ground Truth: 1, Classification: 1, Correct\n",
      "7: Ground Truth: 1, Classification: 1, Correct\n",
      "8: Ground Truth: 1, Classification: 2, Incorrect\n",
      "9: Ground Truth: 1, Classification: 1, Correct\n",
      "10: Ground Truth: 1, Classification: 1, Correct\n",
      "11: Ground Truth: 1, Classification: 1, Correct\n",
      "12: Ground Truth: 1, Classification: 1, Correct\n",
      "13: Ground Truth: 1, Classification: 1, Correct\n",
      "14: Ground Truth: 1, Classification: 1, Correct\n",
      "15: Ground Truth: 1, Classification: 1, Correct\n",
      "16: Ground Truth: 2, Classification: 2, Correct\n",
      "17: Ground Truth: 2, Classification: 2, Correct\n",
      "18: Ground Truth: 2, Classification: 2, Correct\n",
      "19: Ground Truth: 2, Classification: 2, Correct\n",
      "20: Ground Truth: 2, Classification: 2, Correct\n",
      "21: Ground Truth: 2, Classification: 2, Correct\n",
      "22: Ground Truth: 2, Classification: 2, Correct\n",
      "23: Ground Truth: 2, Classification: 2, Correct\n",
      "24: Ground Truth: 2, Classification: 2, Correct\n",
      "25: Ground Truth: 2, Classification: 2, Correct\n",
      "26: Ground Truth: 2, Classification: 2, Correct\n",
      "27: Ground Truth: 3, Classification: 3, Correct\n",
      "28: Ground Truth: 3, Classification: 3, Correct\n",
      "29: Ground Truth: 3, Classification: 3, Correct\n",
      "30: Ground Truth: 3, Classification: 3, Correct\n",
      "31: Ground Truth: 3, Classification: 3, Correct\n",
      "32: Ground Truth: 3, Classification: 3, Correct\n",
      "33: Ground Truth: 3, Classification: 3, Correct\n",
      "34: Ground Truth: 3, Classification: 3, Correct\n",
      "35: Ground Truth: 3, Classification: 3, Correct\n",
      "Accuracy: 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "def Gaussian(x, mu, Sigma):\n",
    "    numerator = math.exp(-0.5 * (x - mu) ** 2 / Sigma)\n",
    "    denominator = math.sqrt(2 * math.pi * Sigma)\n",
    "    return numerator / denominator\n",
    "\n",
    "def getA(x, k, pCk, mu, Sigma):\n",
    "    a = math.log(pCk)\n",
    "    for i in range(13):\n",
    "        a += math.log(Gaussian(float(x[i]), mu[i], Sigma[i]))\n",
    "    return a\n",
    "\n",
    "def softmax(a):\n",
    "    res = []\n",
    "    sum_exp_a = 0.0\n",
    "    for i in range(3):\n",
    "        sum_exp_a += math.exp(a[i])\n",
    "    for i in range(3):\n",
    "        res.append(math.exp(a[i]) / sum_exp_a)\n",
    "    return res\n",
    "\n",
    "classification = []\n",
    "\n",
    "for idx in range(len(test_set)):\n",
    "    item = test_set[idx]\n",
    "    a = []\n",
    "    for i in range(3): # calculate ak of 3 classes\n",
    "        a.append(getA(item[1:], i, pCk[i], training_mu[i], training_Sigma[i]))\n",
    "    P = softmax(a)\n",
    "    \n",
    "    pMax = 0.0\n",
    "    ans_class = -1\n",
    "    for i in range(3):\n",
    "        if P[i] > pMax:\n",
    "            pMax = P[i]\n",
    "            ans_class = i + 1\n",
    "    classification.append(ans_class)\n",
    "\n",
    "correct = 0\n",
    "    \n",
    "for idx in range(len(test_set)):\n",
    "    item = test_set[idx]\n",
    "    print(\"{}: Ground Truth: {}, Classification: {}\".format(idx, int(item[0]), classification[idx]), end=\", \")\n",
    "    if int(item[0]) == classification[idx]:\n",
    "        correct += 1\n",
    "        print('Correct')\n",
    "    else:\n",
    "        print('Incorrect')\n",
    "\n",
    "print(\"Accuracy: {}\".format(float(correct) / len(test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At last, the accuracy is 97.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
